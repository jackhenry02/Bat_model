{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Range Classification with a Spiking Neural Network (snntorch)\n",
    "\n",
    "Classify echo delays (close/medium/far) using a small SNN with surrogate gradients. Input channels: pulse at t=0 and echo at t=delay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import snntorch as snn\n",
    "from snntorch import surrogate as surrogate\n",
    "from snntorch import functional as SF\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Reproducibility\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Synthetic Data Generation (Bat Simulator)\n",
    "- Channel 0: pulse spike at t=0\n",
    "- Channel 1: echo spike at t=delay\n",
    "- Classes map to delay ranges with jitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = 70  # enough to cover max delay + margin\n",
    "class_ranges = {\n",
    "    0: (5, 15),   # Close\n",
    "    1: (20, 35),  # Medium\n",
    "    2: (40, 60),  # Far\n",
    "}\n",
    "\n",
    "def generate_bat_data(num_samples: int):\n",
    "    data = torch.zeros(num_samples, time_steps, 2)\n",
    "    labels = torch.zeros(num_samples, dtype=torch.long)\n",
    "    for i in range(num_samples):\n",
    "        cls = np.random.choice([0, 1, 2])\n",
    "        dmin, dmax = class_ranges[cls]\n",
    "        delay = np.random.randint(dmin, dmax + 1)\n",
    "        jitter = np.random.choice([-1, 0, 1])\n",
    "        delay = int(np.clip(delay + jitter, 0, time_steps - 1))\n",
    "        # Channel 0: pulse at t=0\n",
    "        data[i, 0, 0] = 1.0\n",
    "        # Channel 1: echo at t=delay\n",
    "        data[i, delay, 1] = 1.0\n",
    "        labels[i] = cls\n",
    "    return data, labels\n",
    "\n",
    "# Generate dataset and split\n",
    "num_samples = 1200\n",
    "data, labels = generate_bat_data(num_samples)\n",
    "split = int(0.8 * num_samples)\n",
    "train_data, test_data = data[:split], data[split:]\n",
    "train_labels, test_labels = labels[:split], labels[split:]\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(train_data, train_labels), batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(test_data, test_labels), batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: SNN Architecture\n",
    "- Surrogate gradient (fast sigmoid) enables backprop through spikes.\n",
    "- LIF hidden and output layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 0.9\n",
    "hidden_size = 32\n",
    "num_classes = 3\n",
    "\n",
    "class BatSNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Surrogate gradient lets gradients flow through spike nonlinearity.\n",
    "        self.surrogate_grad = surrogate.fast_sigmoid()\n",
    "        self.fc1 = nn.Linear(2, hidden_size)\n",
    "        self.lif1 = snn.Leaky(beta=beta, spike_grad=self.surrogate_grad)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "        self.lif2 = snn.Leaky(beta=beta, spike_grad=self.surrogate_grad)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [batch, time, 2]\n",
    "        batch_size = x.size(0)\n",
    "        mem1 = torch.zeros(batch_size, hidden_size)\n",
    "        mem2 = torch.zeros(batch_size, num_classes)\n",
    "        spk2_rec = []\n",
    "        for t in range(x.size(1)):\n",
    "            cur = x[:, t, :]\n",
    "            h1 = self.fc1(cur)\n",
    "            spk1, mem1 = self.lif1(h1, mem1)\n",
    "            h2 = self.fc2(spk1)\n",
    "            spk2, mem2 = self.lif2(h2, mem2)\n",
    "            spk2_rec.append(spk2)\n",
    "        spk2_rec = torch.stack(spk2_rec, dim=1)  # [batch, time, classes]\n",
    "        return spk2_rec\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BatSNN().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Training Loop\n",
    "- Loss: Cross-entropy on spike rate (`SF.ce_rate_loss`).\n",
    "- Optimizer: Adam.\n",
    "- Track per-epoch loss and test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "num_epochs = 50\n",
    "\n",
    "def test(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            spk_out = model(x)\n",
    "        # ce_rate_loss expects [time, batch, classes], so permute\n",
    "        spk_out_time_major = spk_out.permute(1, 0, 2)\n",
    "            rates = spk_out.sum(dim=1)  # [batch, classes]\n",
    "            pred = rates.argmax(dim=1)\n",
    "            correct += (pred == y).sum().item()\n",
    "            total += y.numel()\n",
    "    return correct / total\n",
    "\n",
    "train_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        spk_out = model(x)\n",
    "        # ce_rate_loss expects [time, batch, classes], so permute\n",
    "        spk_out_time_major = spk_out.permute(1, 0, 2)\n",
    "        loss = SF.ce_rate_loss()(spk_out_time_major, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item() * x.size(0)\n",
    "    epoch_loss /= len(train_loader.dataset)\n",
    "    train_losses.append(epoch_loss)\n",
    "    acc = test(model, test_loader)\n",
    "    test_accuracies.append(acc)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Loss: {epoch_loss:.4f} | Test Acc: {acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Evaluation & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Training metrics\n",
    "epochs = np.arange(1, num_epochs + 1)\n",
    "fig, ax1 = plt.subplots(figsize=(7, 3))\n",
    "ax1.plot(epochs, train_losses, color='tab:blue', label='Loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss', color='tab:blue')\n",
    "ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(epochs, test_accuracies, color='tab:orange', label='Accuracy')\n",
    "ax2.set_ylabel('Accuracy', color='tab:orange')\n",
    "ax2.tick_params(axis='y', labelcolor='tab:orange')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.title(\"Training Loss and Test Accuracy\")\n",
    "plt.show()\n",
    "\n",
    "# 2) Spike raster on a random test sample\n",
    "model.eval()\n",
    "idx = np.random.randint(0, len(test_data))\n",
    "sample_x = test_data[idx:idx+1].to(device)\n",
    "sample_y = test_labels[idx].item()\n",
    "with torch.no_grad():\n",
    "    spk_out = model(sample_x)\n",
    "spk_out_cpu = spk_out.cpu().squeeze(0)  # [time, classes]\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(7, 4), sharex=True)\n",
    "spikeplot.raster(sample_x.cpu().squeeze(0), ax=axes[0])\n",
    "axes[0].set_title(f\"Input Spikes (True class: {sample_y})\")\n",
    "axes[0].set_ylabel(\"Channel\")\n",
    "\n",
    "spikeplot.raster(spk_out_cpu, ax=axes[1])\n",
    "axes[1].set_title(\"Output Spikes (Classes 0,1,2)\")\n",
    "axes[1].set_xlabel(\"Time step\")\n",
    "axes[1].set_ylabel(\"Class\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3) Confusion matrix on test set\n",
    "all_preds = []\n",
    "all_trues = []\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        x = x.to(device)\n",
    "        spk_out = model(x)\n",
    "        rates = spk_out.sum(dim=1)\n",
    "        preds = rates.argmax(dim=1).cpu().numpy()\n",
    "        all_preds.extend(preds)\n",
    "        all_trues.extend(y.numpy())\n",
    "\n",
    "cm = confusion_matrix(all_trues, all_preds, labels=[0,1,2])\n",
    "fig, ax = plt.subplots(figsize=(4, 3))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=['Close','Med','Far'], yticklabels=['Close','Med','Far'], ax=ax)\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('True')\n",
    "ax.set_title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}